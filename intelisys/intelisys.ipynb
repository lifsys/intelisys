{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intelisys import Intelisys, safe_json_loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:51:11 - Intelisys - INFO - Log level set to: DEBUG\n",
      "2024-08-10 09:51:11 - Intelisys - INFO - Initializing Intelisys instance 'Intelisys' with provider=anthropic, model=None\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - Intelisys initialized with: name=Intelisys, max_history_words=10000, max_words_per_message=None, json_mode=False, stream=False, use_async=False, max_retry=10, temperature=0, max_tokens=None\n",
      "2024-08-10 09:51:11 - Intelisys - INFO - Chat method called\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - User input: Hello, how are you?...\n",
      "2024-08-10 09:51:11 - Intelisys - INFO - get_response method called\n",
      "2024-08-10 09:51:11 - Intelisys - INFO - Adding message with role: user\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - Message content: Hello, how are you?...\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - API call params: {'model': 'claude-3-5-sonnet-20240620', 'messages': [{'role': 'user', 'content': 'Hello, how are you?'}], 'stream': False, 'temperature': 0, 'max_tokens': 8192}\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - API call params: {'model': 'claude-3-5-sonnet-20240620', 'messages': [{'role': 'user', 'content': 'Hello, how are you?'}], 'stream': False, 'temperature': 0, 'max_tokens': 8192}\n",
      "2024-08-10 09:51:11 - Intelisys - INFO - Initializing client for provider: anthropic\n",
      "2024-08-10 09:51:11 - Intelisys - DEBUG - Client initialized: Anthropic\n",
      "2024-08-10 09:51:12 - Intelisys - INFO - Handling response\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - Handling non-stream response\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - Handling non-stream response\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - Raw assistant response: Hello! I'm doing well, thank you for asking. As an AI assistant, I don't have feelings, but I'm functioning properly and ready to help you with any questions or tasks you might have. How can I assist you today?\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - Final processed assistant response: Hello! I'm doing well, thank you for asking. As an AI assistant, I don't have feelings, but I'm functioning properly and ready to help you with any questions or tasks you might have. How can I assist you today?\n",
      "2024-08-10 09:51:12 - Intelisys - INFO - Adding message with role: assistant\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - Message content: Hello! I'm doing well, thank you for asking. As an...\n",
      "2024-08-10 09:51:12 - Intelisys - INFO - Trimming history\n",
      "2024-08-10 09:51:12 - Intelisys - DEBUG - History trimmed. Current word count: 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you for asking. As an AI assistant, I don't have feelings, but I'm functioning properly and ready to help you with any questions or tasks you might have. How can I assist you today?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Synchronous usage\n",
    "intelisys = Intelisys()\n",
    "response = intelisys.chat(\"Hello, how are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'greeting': 'Hello!',\n",
       " 'status': \"I'm doing well, thank you for asking.\",\n",
       " 'self_description': {'type': 'AI assistant',\n",
       "  'feelings': \"I don't have feelings\",\n",
       "  'functionality': \"I'm functioning properly\"},\n",
       " 'offer': 'ready to help you with any questions or tasks you might have',\n",
       " 'question': 'How can I assist you today?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safe_json_loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resume lacks explicit army rank; describes leadership roles without specifying rank.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Template usage\n",
    "response = intelisys.template_chat(\n",
    "    template=\"Summarize this in {{words}} words: {{text}}\",\n",
    "    render_data={\"words\": 10, \"text\": \"After carefully reviewing the provided resume, I don't see any explicit mention of a specific army rank. The document describes various military and civilian roles and responsibilities, but does not state a particular rank like Lieutenant, Captain, Major, etc. \\nThe experience described suggests the individual has had significant leadership roles in the U.S. Army and Army Reserve, including positions like: Chief of the Central Team in the Army Reserve Sustainment Command Transportation Officer in the US Army Reserve Deployment Support Command Director of Logistics for Area Support Group - Kuwait Contingency Contracting Officer in Southwest Asia. While these roles imply a relatively senior position, without an explicitly stated rank, I cannot confirm any specific army rank from the information provided. The focus seems to be more on describing job responsibilities and accomplishments rather than military rank progression.\"}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 09:51:15 - Intelisys - WARNING - json_mode=True is set for provider 'anthropic'. Note that only OpenAI has native JSON mode support. For other providers, we'll attempt to parse the response as JSON using safe_json_loads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Alice', 'greeting': 'Hello!', 'mood': \"I'm doing well, thank you for asking.\", 'current_status': 'Ready to assist', 'timestamp': '2023-05-09T12:34:56Z'}\n"
     ]
    }
   ],
   "source": [
    "intelisys = Intelisys(json_mode=True)\n",
    "\n",
    "# Set a default template\n",
    "intelisys.set_default_template(\"Return JSON, {{ name }}! {{ question }}\")\n",
    "\n",
    "# Use the template in a chat\n",
    "response = intelisys.template_chat(\n",
    "    render_data={\"name\": \"Alice\", \"question\": \"How are you today?\"}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Develop test cases\\n\\nEngineer preliminary prompt\\n\\nTest prompt against cases\\n\\nRefine prompt\\n\\nTest against held-out evals\\n\\nShip polished prompt\\n\\nDon't forget edge cases!\\n\\nEVALS!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image OCR example\n",
    "intelisys = Intelisys(provider=\"openrouter\", model=\"google/gemini-pro-vision\")  # Make sure to use a model that supports image processing\n",
    "result = (intelisys\n",
    "    .image(\"https://mintlify.s3-us-west-1.amazonaws.com/anthropic/images/how-to-prompt-eng.png\")\n",
    "    .chat(\"Please provide the complete text in the following image(s).\")\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
